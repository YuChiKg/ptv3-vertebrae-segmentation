{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the Training Result \n",
    " - ptv3_small\n",
    " - with 8 * Specimens\n",
    " - with 6 classes: change dataloader to ptv3_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random\n",
    "import numpy as np\n",
    "import os\n",
    "from data_utils.augmentation import NormalizeFeatures, AdjustRGBColor\n",
    "from data_utils.SpineDepthDataLoader_ptv3 import TrainDataset, TestDataset\n",
    "# from data_utils.SpineDepthDataLoader_ptv3_6 import TrainDataset, TestDataset\n",
    "from torchvision.transforms import Compose\n",
    "from ptv3_model import PTv3Wrap\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproducability\n",
    "manual_seed = 42     \n",
    "random.seed(manual_seed)    # Python's random module\n",
    "np.random.seed(manual_seed)     # NumPy random module\n",
    "torch.manual_seed(manual_seed)      # PyTorch CPU\n",
    "torch.cuda.manual_seed_all(manual_seed)     # PyTorch GPU (for all devices)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# For DataLoader Reproducability\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "# same sequence of random numbers \n",
    "g = torch.Generator()\n",
    "g.manual_seed(manual_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "NUM_CHANNELS = 6\n",
    "NUM_POINT = 10000\n",
    "BATCH_SIZE = 2\n",
    "NUM_WORKERS = 12\n",
    "test_specimen_idx = 3\n",
    "adjust_strength = 0.3\n",
    "randomize_rate = 0.5\n",
    "\n",
    "def _device():\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device = _device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ptv3_small(\n",
    "    num_classes: int = NUM_CLASSES, \n",
    "    in_channels: int = NUM_CHANNELS, \n",
    "    num_points: int = NUM_POINT, \n",
    "    patch_size: int = 1024, \n",
    "    device: torch.device = _device()\n",
    "):\n",
    "    # Encoder settings\n",
    "    enc_channels = (32, 64, 128, 256)\n",
    "    enc_depths = (2, 2, 2, 2)\n",
    "    enc_num_head = (2, 4, 8, 16)\n",
    "    enc_patch_size = (patch_size,) * 4\n",
    "    stride = (2, 2, 2)\n",
    "\n",
    "    # Decoder settings\n",
    "    dec_channels = (16, 64, 128)\n",
    "    dec_depths = (2, 2, 2)\n",
    "    dec_num_head = (4, 8, 16)\n",
    "    dec_patch_size = (patch_size,) * 3\n",
    "\n",
    "    # Initialize the PTv3Wrap model\n",
    "    model = PTv3Wrap(\n",
    "        num_classes=num_classes,\n",
    "        in_channels=in_channels,\n",
    "        num_points=num_points,\n",
    "        enc_channels=enc_channels,\n",
    "        enc_depths=enc_depths,\n",
    "        enc_num_head=enc_num_head,\n",
    "        enc_patch_size=enc_patch_size,\n",
    "        dec_channels=dec_channels,\n",
    "        dec_depths=dec_depths,\n",
    "        dec_num_head=dec_num_head,\n",
    "        dec_patch_size=dec_patch_size,\n",
    "        stride=stride,\n",
    "    )\n",
    "\n",
    "    return model.to(device)\n",
    "\n",
    "class WeightedFocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=5.0, reduction='mean'):\n",
    "        super(WeightedFocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, seg_pred, targets, alpha):\n",
    "        \"\"\"\n",
    "        seg_pred: Logits from the model [B, C] where C = number of classes.\n",
    "        targets: Ground truth labels [B].\n",
    "        alpha: Class weights (1D tensor) for weighted focal loss.\n",
    "        \"\"\"\n",
    "        # return correspond class weight depands on the target label\n",
    "        alpha = alpha.gather(0, targets.view(-1)).unsqueeze(1) \n",
    "        \n",
    "        # Calculate log-softmax for stability\n",
    "        log_prob = F.log_softmax(seg_pred, dim=-1) \n",
    "        prob = torch.exp(log_prob)  # [B, C]\n",
    "\n",
    "        # Gather the log probabilities for the correct classes\n",
    "        log_prob = log_prob.gather(1, targets.unsqueeze(1))  # for pt \n",
    "        prob = prob.gather(1, targets.unsqueeze(1))  # [B, 1]\n",
    "\n",
    "        # Compute focal loss\n",
    "        focal_loss = -alpha * (1 - prob) ** self.gamma * log_prob\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_train_dir = f'/home/travail/ptv3-vertebrae-segmentation/log/ptv3_small/class_2/num_examples_25/S_3/checkpoints/model.pth'\n",
    "checkpoint = torch.load(log_train_dir)\n",
    "print(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training progress refers to 'model.pth'\n",
    "train_loss = checkpoint['training_loss']\n",
    "train_accuracy = checkpoint['train_accuracy']\n",
    "\n",
    "eval_loss = checkpoint['eval_loss']\n",
    "eval_accuracy = checkpoint['eval_accuracy']\n",
    "\n",
    "\n",
    "epoch = checkpoint['epoch']\n",
    "print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'train_loss' and 'train_accuracy' are lists or arrays containing values per epoch\n",
    "# Convert CUDA tensors to CPU before plotting (if necessary)\n",
    "training_loss_epoch = [loss.detach().cpu().numpy() if isinstance(loss, torch.Tensor) else loss for loss in train_loss]\n",
    "train_accuracy_epoch = [acc.detach().cpu().numpy() if isinstance(acc, torch.Tensor) else acc for acc in train_accuracy]\n",
    "\n",
    "validation_loss_epoch = [loss.detach().cpu().numpy() if isinstance(loss, torch.Tensor) else loss for loss in eval_loss]\n",
    "validation_accuracy_epoch = [acc.detach().cpu().numpy() if isinstance(acc, torch.Tensor) else acc for acc in eval_accuracy]\n",
    "\n",
    "\n",
    "# Create a figure with 2 subplots, sharing the x-axis\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(10, 7))\n",
    "\n",
    "# Loss\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.plot(range(len(training_loss_epoch)), training_loss_epoch, label=\"Train Loss\", color=\"blue\")\n",
    "ax1.plot(range(len(validation_loss_epoch)), validation_loss_epoch, label=\"Eval Loss\", color=\"orange\")\n",
    "ax1.tick_params(axis='y')\n",
    "ax1.set_title('Training Loss and Validation Loss per Epoch')\n",
    "\n",
    "# Accuracy\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.plot(range(len(train_accuracy_epoch)), train_accuracy_epoch, label=\"Train Accuracy\", color=\"blue\")\n",
    "ax2.plot(range(len(validation_accuracy_epoch)), validation_accuracy_epoch, label=\"Eval Accuracy\", color=\"orange\")\n",
    "ax2.tick_params(axis='y')\n",
    "ax2.set_title('Training Accuracy and Validation Accuracy per Epoch')\n",
    "\n",
    "# Adding legends\n",
    "ax1.legend(loc='best')\n",
    "ax2.legend(loc='best')\n",
    "\n",
    "# Adjust layout to avoid title overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_best_dir = f'/home/travail/ptv3-vertebrae-segmentation/log/ptv3_small/class_2/num_examples_25/S_3/checkpoints/best_model.pth'\n",
    "checkpoint = torch.load(log_best_dir)\n",
    "print(checkpoint.keys())\n",
    "model = ptv3_small()\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# [-] made a mistake of typing error already changed in 'train_sem_seg_ptv3.py (save best_model state)\n",
    "DSC = checkpoint['Vertebrae DSC']\n",
    "print(' - Vertebrae DSC: {:.3f}'.format(DSC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation \n",
    "**Notes**\n",
    "- choose test_specimen_idx = i , i=[2,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug_dir = '/home/travail/PointTransformerV3/SpineDepth_labeled_symlink'\n",
    "S3_vis_dir = '/home/travail/ptv3-vertebrae-segmentation/S3_vis'\n",
    "\n",
    "# Go to augmentation.py to change 'adjust_strength'\n",
    "transforms = Compose([\n",
    "    # AdjustRGBColor(adjust_strength=adjust_strength, randomize_rate = randomize_rate),\n",
    "    NormalizeFeatures(),\n",
    "])\n",
    "\n",
    "# TRAIN_DATASET = TrainDataset(root_dir=debug_dir, num_points=NUM_POINT, test_specimen_idx=test_specimen_idx, sample_ratio=0.2, transforms=transforms)\n",
    "TEST_DATASET = TestDataset(root_dir=S3_vis_dir, num_points=NUM_POINT, test_specimen_idx=test_specimen_idx, transforms=transforms)\n",
    "\n",
    "# trainDataLoader = torch.utils.data.DataLoader(TRAIN_DATASET, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, worker_init_fn=seed_worker, generator=g)\n",
    "testDataLoader = torch.utils.data.DataLoader(TEST_DATASET, batch_size=BATCH_SIZE, shuffle=False, drop_last=True, num_workers=NUM_WORKERS, pin_memory=True, worker_init_fn=seed_worker, generator=g)\n",
    "# train_weights = torch.Tensor(TRAIN_DATASET.labelweights).to(device)\n",
    "test_weights = torch.Tensor(TEST_DATASET.labelweights).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For all the test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gt_labels = []\n",
    "all_pred_labels = []\n",
    "eval_loss_list = []\n",
    "eval_accuracy_list = []\n",
    "\n",
    "loss_fn = WeightedFocalLoss(gamma=5).to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    eval_total_correct = 0\n",
    "    eval_total_seen = 0\n",
    "    eval_loss = 0\n",
    "    # Load one batch from the test data\n",
    "    for batch, (eval_points, eval_target) in tqdm(enumerate(testDataLoader), total=len(testDataLoader)):\n",
    "        ## prepare input_dict:\n",
    "        grid_size=0.01\n",
    "        coord = eval_points[:, :, :3].float().to(device)\n",
    "        feat =  eval_points[:, :, 0:6].float().to(device)\n",
    "        # labels = target\n",
    "        input_dict = {\n",
    "        \"coord\": coord.view(-1, 3),  # [x, y, z]\n",
    "        \"feat\": feat.view(-1, 6),  # [x, y, z, r, g, b]\n",
    "        # \"label\": torch.tensor(labels, dtype=torch.long).to(device),  # Labels (binary)\n",
    "        \"batch\": torch.repeat_interleave(torch.arange(eval_points.size(0)), eval_points.size(1)).to(device),\n",
    "        }\n",
    "        # print(f\"batch shape: {input_dict['batch'].shape}\")\n",
    "        # Calculate grid coordinates\n",
    "        input_dict[\"grid_coord\"] = torch.div(\n",
    "                    input_dict[\"coord\"] - input_dict[\"coord\"].min(0)[0],\n",
    "                    grid_size, rounding_mode='trunc'\n",
    "                ).int().to(device)\n",
    "        # print(f\"bf reshape: Grid coord shape: {input_dict['grid_coord'].shape}\")\n",
    "        input_dict[\"grid_coord\"] = input_dict[\"grid_coord\"].view(-1,3)\n",
    "        # print(f\"after reshape: Grid coord shape: {input_dict['grid_coord'].shape}\")\n",
    "\n",
    "        ##########%%%%%%%%%%%%##############            \n",
    "        # put target to device\n",
    "        eval_target = eval_target.long().to(device)\n",
    "        pred, output = model(input_dict)\n",
    "        seg_pred = pred.contiguous().view(-1, NUM_CLASSES)\n",
    "        eval_target = eval_target.view(-1, 1)[:, 0]\n",
    "        loss = loss_fn(seg_pred, eval_target, test_weights)\n",
    "        ############%%%%%%%%%%%########            \n",
    "        # pred_val = np.argmax(pred_val, 2)\n",
    "        pred_choice = seg_pred.cpu().data.max(1)[1].numpy()\n",
    "        # print(f\"eval_pred_choice: {pred_choice}\")\n",
    "        batch_label = eval_target.view(-1, 1)[:, 0].cpu().data.numpy()\n",
    "        # print(f\"eval_ground_truth: {batch_label}\")\n",
    "\n",
    "        eval_correct = np.sum((pred_choice == batch_label))\n",
    "        eval_total_correct += eval_correct\n",
    "        eval_total_seen += (BATCH_SIZE * NUM_POINT)\n",
    "        eval_loss += loss.item()\n",
    "\n",
    "        # For confusion matrix calculation, collect ground truth and predicted labels\n",
    "        all_gt_labels.append(batch_label.flatten())  # Flatten ground truth labels\n",
    "        all_pred_labels.append(pred_choice.flatten())   # Flatten predicted labels\n",
    "\n",
    "    # DEBUGGING \n",
    "    eval_loss /= len(testDataLoader)\n",
    "    print(f'Eval Loss: {eval_loss:.4f}')\n",
    "    eval_accuracy = eval_total_correct / float(eval_total_seen)\n",
    "    print(f'Eval Accuracy: {eval_accuracy:.4f}')    \n",
    "    eval_loss_list.append(eval_loss)\n",
    "    eval_accuracy_list.append(eval_accuracy)\n",
    "        \n",
    "    # Concatenate all collected labels to compute confusion matrix\n",
    "    all_gt_labels = np.concatenate(all_gt_labels)\n",
    "    all_pred_labels = np.concatenate(all_pred_labels)\n",
    "\n",
    "    CM = confusion_matrix(all_gt_labels, all_pred_labels, labels=np.arange(NUM_CLASSES))\n",
    "    # Dynamic range for vertebrae classes (1 to NUM_CLASSES - 1)\n",
    "    vertebrae_range = range(1, NUM_CLASSES)\n",
    "\n",
    "    # Calculate TP, FN, FP, TN dynamically\n",
    "    tp = np.sum([CM[i, i] for i in vertebrae_range])  # True positives for vertebrae\n",
    "    fn = np.sum([CM[i, j] for i in vertebrae_range for j in range(NUM_CLASSES) if j != i])  # False negatives\n",
    "    fp = np.sum([CM[j, i] for i in vertebrae_range for j in range(NUM_CLASSES) if j != i])  # False positives\n",
    "    tn = CM[0, 0]  # True negatives (non-vertebrae correctly classified)\n",
    "    acc=np.sum(np.diag(CM)/np.sum(CM))\n",
    "    recall =tp/(tp+fn)\n",
    "    precision=tp/(tp+fp)\n",
    "    IoU = tp/ (tp+fn+fp)\n",
    "    DSC = 2 * tp / (2 * tp + fn + fp)\n",
    "    f1 = (2 * recall * precision) / (recall + precision)\n",
    "\n",
    "    # Print with 3 decimal precision\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(CM)\n",
    "\n",
    "    print('\\nTestset Accuracy (mean): {:.3f} %'.format(100 * acc))\n",
    "    print('- Recall     : {:.3f}'.format(recall))\n",
    "    print('- Precision  : {:.3f}'.format(precision))\n",
    "    print('- F1 Score   : {:.3f}'.format(f1))\n",
    "    print('- Vertebrae IoU: {:.3f}'.format(IoU))\n",
    "    print('- Vertebrae DSC: {:.3f}'.format(DSC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size = number of frame = 6\n",
    "\n",
    "point_clouds = eval_points.cpu().numpy()\n",
    "print(f'point cloud per batch: {point_clouds.shape}')   #(batch_size, num_point, features)\n",
    "\n",
    "## the last batch might have only 1 batch (instead of 2)\n",
    "pred_label = pred_choice.reshape(eval_points.size(0), eval_points.size(1))\n",
    "print(f'pred label: {pred_label.shape}')    #(batch_size, num_point)\n",
    "\n",
    "gd_label = eval_target.cpu().numpy()\n",
    "gd_label = gd_label.reshape(eval_points.size(0), eval_points.size(1))\n",
    "print(f'ground truth label: {gd_label.shape}')  #(batch_size, num_point)\n",
    "\n",
    "# Add new dimension\n",
    "pred_label = pred_label[:, :, np.newaxis]  # (batch_size, num_point, 1)\n",
    "gd_label = gd_label[:, :, np.newaxis]      # (batch_size, num_point, 1)\n",
    "\n",
    "# Final shape: (6, 1024, 11 = (9+1+1))\n",
    "vis_pc = np.concatenate((point_clouds, pred_label, gd_label), axis=2)\n",
    "print(f'visualize point clouds: {vis_pc.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2 classes Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = vis_pc[1]  # Shape: (num_points, 11)\n",
    "\n",
    "# Separate points based on their labels\n",
    "gt_label_1 = batch_idx[batch_idx[:, 10] == 1][:, :3]  # Ground truth label = 1\n",
    "gt_label_0 = batch_idx[batch_idx[:, 10] == 0][:, :3]  # Ground truth label = 0\n",
    "pred_label_1 = batch_idx[batch_idx[:, 9] == 1][:, :3]  # Predicted label = 1\n",
    "pred_label_0 = batch_idx[batch_idx[:, 9] == 0][:, :3] # Predicted label = 1\n",
    "\n",
    "# Create Scatter3D plots for each group\n",
    "trace_gt_1 = go.Scatter3d(\n",
    "    x=gt_label_1[:, 0], y=gt_label_1[:, 1], z=-gt_label_1[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=2, color='blue'),\n",
    "    name='Ground Truth Vertebrae (Label = 1)'\n",
    ")\n",
    "\n",
    "trace_gt_0 = go.Scatter3d(\n",
    "    x=gt_label_0[:, 0], y=gt_label_0[:, 1], z=-gt_label_0[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=2, color='gray'),\n",
    "    name='Ground Truth Others (Label = 0) '\n",
    ")\n",
    "\n",
    "trace_pred_1 = go.Scatter3d(\n",
    "    x=pred_label_1[:, 0], y=pred_label_1[:, 1], z=-pred_label_1[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=1.5, color='red'),\n",
    "    name='Predicted Vertebrae (Label = 1)'\n",
    ")\n",
    "\n",
    "# trace_pred_0 = go.Scatter3d(\n",
    "#     x=pred_label_0[:, 0], y=pred_label_0[:, 1], z=pred_label_0[:, 2],\n",
    "#     mode='markers',\n",
    "#     marker=dict(size=2.5, color='gray'),\n",
    "#     name='Predicted Others (Label = 0)'\n",
    "# )\n",
    "\n",
    "# Combine all traces\n",
    "fig = go.Figure(data=[trace_gt_1, trace_gt_0, trace_pred_1])\n",
    "\n",
    "# Set layout for the figure\n",
    "fig.update_layout(\n",
    "    title=\"3D Point Cloud Visualization with Ground Truth and Predictions\",\n",
    "    scene=dict(\n",
    "        xaxis_title='X',\n",
    "        yaxis_title='Y',\n",
    "        zaxis_title='Z'),\n",
    "    height=750,\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_idx = vis_pc[0]  # Shape: (num_points, 11)\n",
    "\n",
    "# # Separate points based on their labels\n",
    "# gt_label_1 = batch_idx[batch_idx[:, 10] == 1][:, :3]  # Ground truth label = 1\n",
    "# gt_label_0 = batch_idx[batch_idx[:, 10] == 0][:, :3]  # Ground truth label = 0\n",
    "# pred_label_1 = batch_idx[batch_idx[:, 9] == 1][:, :3]  # Predicted label = 1\n",
    "# pred_label_0 = batch_idx[batch_idx[:, 9] == 0][:, :3] # Predicted label = 1\n",
    "\n",
    "# # Create subplot layout: 1 row, 2 columns\n",
    "# fig = make_subplots(\n",
    "#     rows=1, cols=2,\n",
    "#     specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}]],\n",
    "#     subplot_titles=(\"Ground Truth\", \"Prediction\")\n",
    "# )\n",
    "\n",
    "# # Add ground truth traces to the first subplot (column 1)\n",
    "# fig.add_trace(\n",
    "#     go.Scatter3d(\n",
    "#         x=gt_label_1[:, 0], y=gt_label_1[:, 1], z=gt_label_1[:, 2],\n",
    "#         mode='markers',\n",
    "#         marker=dict(size=2, color='gold'),\n",
    "#         name='GT Vertebrae (Label = 1)'\n",
    "#     ), row=1, col=1\n",
    "# )\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter3d(\n",
    "#         x=gt_label_0[:, 0], y=gt_label_0[:, 1], z=gt_label_0[:, 2],\n",
    "#         mode='markers',\n",
    "#         marker=dict(size=2, color='gray'),\n",
    "#         name='GT Others (Label = 0)'\n",
    "#     ), row=1, col=1\n",
    "# )\n",
    "\n",
    "# # Add prediction traces to the second subplot (column 2)\n",
    "# fig.add_trace(\n",
    "#     go.Scatter3d(\n",
    "#         x=pred_label_1[:, 0], y=pred_label_1[:, 1], z=pred_label_1[:, 2],\n",
    "#         mode='markers',\n",
    "#         marker=dict(size=2, color='gold'),\n",
    "#         name='Pred Vertebrae (Label = 1)'\n",
    "#     ), row=1, col=2\n",
    "# )\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter3d(\n",
    "#         x=pred_label_0[:, 0], y=pred_label_0[:, 1], z=pred_label_0[:, 2],\n",
    "#         mode='markers',\n",
    "#         marker=dict(size=2, color='gray'),\n",
    "#         name='Pred Others (Label = 0)'\n",
    "#     ), row=1, col=2\n",
    "# )\n",
    "\n",
    "# # Set layout for the figure\n",
    "# fig.update_layout(\n",
    "#     title=\"3D Point Cloud: Ground Truth vs Prediction\",\n",
    "#     scene=dict(xaxis_title='X', yaxis_title='Y', zaxis_title='Z'),\n",
    "#     height=800,\n",
    "# )\n",
    "\n",
    "# # Show the figure\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6 classes Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_idx = vis_pc[1]  # Shape: (num_points, 11)\n",
    "\n",
    "# # Colors for ground truth (lighter) and predictions (darker)\n",
    "# gt_colors = ['lightslategray', 'lightcoral', 'lightyellow', 'mistyrose', 'lightblue', 'lightgreen']\n",
    "# pred_colors = ['lightslategray', 'red', 'orange', 'hotpink', 'blue', 'green']\n",
    "# # Separate points based on their labels and create traces\n",
    "# ground_truth_traces = []\n",
    "# prediction_traces = []\n",
    "\n",
    "# for label in range(6):  # Iterate over labels 0 to 5\n",
    "#     # Filter points for the current ground truth label\n",
    "#     gt_points = batch_idx[batch_idx[:, 10] == label][:, :3]\n",
    "#     if gt_points.size > 0:  # Only add trace if there are points\n",
    "#         ground_truth_traces.append(\n",
    "#             go.Scatter3d(\n",
    "#                 x=gt_points[:, 0], y=gt_points[:, 1], z=-gt_points[:, 2], # reverse z-axis\n",
    "#                 mode='markers',\n",
    "#                 marker=dict(size=1.5, color=gt_colors[label]),\n",
    "#                 name=f'Ground Truth (Label = {label})'\n",
    "#             )\n",
    "#         )\n",
    "    \n",
    "#     # Filter points for the current predicted label\n",
    "#     pred_points = batch_idx[batch_idx[:, 9] == label][:, :3]\n",
    "#     if pred_points.size > 0:  # Only add trace if there are points\n",
    "#         prediction_traces.append(\n",
    "#             go.Scatter3d(\n",
    "#                 x=pred_points[:, 0], y=pred_points[:, 1], z=-pred_points[:, 2], # reverse z-axis\n",
    "#                 mode='markers',\n",
    "#                 marker=dict(size=1.5, color=pred_colors[label], symbol='cross'),\n",
    "#                 name=f'Predicted (Label = {label})'\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "# # Combine all traces\n",
    "# fig = go.Figure(data=ground_truth_traces + prediction_traces)\n",
    "\n",
    "# # Set layout for the figure\n",
    "# fig.update_layout(\n",
    "#     title=\"3D Point Cloud Visualization with Ground Truth and Predictions (6 Classes)\",\n",
    "#     scene=dict(\n",
    "#         xaxis=dict(\n",
    "#             title='X',\n",
    "#             backgroundcolor=\"slategray\"\n",
    "#         ),\n",
    "#         yaxis=dict(\n",
    "#             title='Y',\n",
    "#             backgroundcolor=\"slategray\"\n",
    "#         ),\n",
    "#         zaxis=dict(\n",
    "#             title='Z',\n",
    "#             backgroundcolor=\"slategray\"\n",
    "#         ),\n",
    "#     ),\n",
    "#     height=750,\n",
    "# )\n",
    "\n",
    "# # Show the figure\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_idx = vis_pc[1]  # Shape: (num_points, 11)\n",
    "\n",
    "# # Colors for ground truth (lighter) and predictions (darker)\n",
    "# # gt_colors = ['lightslategray', 'lightcoral', 'lightyellow', 'mistyrose', 'lightblue', 'lightgreen']\n",
    "# gt_colors = ['gray', 'red', 'orange', 'pink', 'blue', 'green']\n",
    "# pred_colors = ['gray', 'red', 'orange', 'pink', 'blue', 'green']\n",
    "\n",
    "# # Create subplot layout: 1 row, 2 columns\n",
    "# fig = make_subplots(\n",
    "#     rows=1, cols=2,\n",
    "#     specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}]],\n",
    "#     subplot_titles=(\"Ground Truth\", \"Prediction\")\n",
    "# )\n",
    "\n",
    "# # Add ground truth traces to the first subplot (column 1)\n",
    "# for label in range(6):  # Iterate over labels 0 to 5\n",
    "#     gt_points = batch_idx[batch_idx[:, 10] == label][:, :3]\n",
    "#     if gt_points.size > 0:  # Only add trace if there are points\n",
    "#         fig.add_trace(\n",
    "#             go.Scatter3d(\n",
    "#                 x=gt_points[:, 0], y=gt_points[:, 1], z=-gt_points[:, 2], # reverse z-axis\n",
    "#                 mode='markers',\n",
    "#                 marker=dict(size=1.5, color=gt_colors[label]),\n",
    "#                 name=f'GT (Label = {label})'\n",
    "#             ), row=1, col=1\n",
    "#         )\n",
    "\n",
    "# # Add prediction traces to the second subplot (column 2)\n",
    "# for label in range(6):  # Iterate over labels 0 to 5\n",
    "#     pred_points = batch_idx[batch_idx[:, 9] == label][:, :3]\n",
    "#     if pred_points.size > 0:  # Only add trace if there are points\n",
    "#         fig.add_trace(\n",
    "#             go.Scatter3d(\n",
    "#                 x=pred_points[:, 0], y=pred_points[:, 1], z=-pred_points[:, 2], # reverse z-axis\n",
    "#                 mode='markers',\n",
    "#                 marker=dict(size=1.5, color=pred_colors[label]),\n",
    "#                 name=f'Pred (Label = {label})'\n",
    "#             ), row=1, col=2\n",
    "#         )\n",
    "\n",
    "# # Set layout for the figure\n",
    "# fig.update_layout(\n",
    "#     title=\"3D Point Cloud: Ground Truth vs Prediction (6 Classes)\",\n",
    "#     scene=dict(\n",
    "#         xaxis_title='X',\n",
    "#         yaxis_title='Y',\n",
    "#         zaxis_title='Z'\n",
    "#     ),\n",
    "#     height=800,\n",
    "#     width=1200,\n",
    "# )\n",
    "\n",
    "# # Show the figure\n",
    "# fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
